{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cara sebelumnya sebenaranya adalah cara yang lebih mudah.**\n",
    "\n",
    "Apa yang akan dilakukan di sini adalah sekedar untuk mengetahui bagaimana cara chain bekerja di belakang layar. Cara kali ini akan lebih lama karena kita tidak menggunakan langchain expression language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableSequence\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(model=\"Llama3.2:1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a comedian who tells joke about {topic}\"),\n",
    "    (\"human\", \"Tell me {count} jokes\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual runnable (steps in chains under the hood)\n",
    "format_prompt = RunnableLambda(lambda x: prompt_template.format_prompt(**x))\n",
    "invoke_model = RunnableLambda(lambda x: model.invoke(x.to_messages()))\n",
    "parse_output = RunnableLambda(lambda x: x.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RunnableSequance (equivalent to the LCEL chain)\n",
    "chain = RunnableSequence(first=format_prompt, middle=[invoke_model], last=parse_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are six jokes about cats:\n",
      "\n",
      "1. Why did the cat join a band? Because it wanted to be the purr-cussionist!\n",
      "2. Why did the cat take a selfie? To capture its paws-itive side!\n",
      "3. What do you call a group of cats playing instruments? A mew-sical band!\n",
      "4. Why did the cat go to the gym? To get some paws-itive reinforcement!\n",
      "5. What do you call a cat that's a good listener? A purr-fect counselor!\n",
      "6. Why did the cat climb up the tree? To paws and reflect on its life!\n"
     ]
    }
   ],
   "source": [
    "# Run Chain\n",
    "response = chain.invoke({\"topic\": \"cat\", \"count\": 6})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three jokes about lawyers:\n",
      "\n",
      "1. Why did the lawyer bring a ladder to court?\n",
      "\n",
      "Because he wanted to take his argument to the next level!\n",
      "\n",
      "2. What do you call a group of cows filing a lawsuit against a rancher?\n",
      "\n",
      "A herd of plaintiffs!\n",
      "\n",
      "3. Why did the lawyer's cat join a band?\n",
      "\n",
      "Because it wanted to be the purr-cussionist, but the gigs were all paw-some and he couldn't paws for attention!\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\"topic\": \"lawyers\", \"count\": 3})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So.. jadi pada dasarnya, menggunakan `prompt_template | model | StrOutputParser()` jauh lebih simpel karena menggunakan langchain expression dibandingkan menggunakan `RunnableLambda` dan `RunnableSequence`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
