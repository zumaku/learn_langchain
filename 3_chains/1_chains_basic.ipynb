{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(model=\"Llama3.2:1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a comedian who tells joke about {topic}\"),\n",
    "    (\"human\", \"Tell me {count} jokes\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 1**\n",
    "\n",
    "Dengan menggunakan `prompt_template` dan `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Lawyers, the ultimate buzzkill. Here are three jokes for you:\\n\\n1. Why did the lawyer's dog go to the vet?\\n\\nBecause it was feeling ruff!\\n\\n2. Why did the lawyer become a baker?\\n\\nBecause he wanted to make some dough... and also because he heard it was a paws-itive way to practice his skills!\\n\\n3. What do you call a lawyer who's always getting sued?\\n\\nYour worst nightmare â€“ a defendant!\" additional_kwargs={} response_metadata={'model': 'Llama3.2:1b', 'created_at': '2024-12-04T06:26:22.802234Z', 'done': True, 'done_reason': 'stop', 'total_duration': 54744102400, 'load_duration': 12101640400, 'prompt_eval_count': 39, 'prompt_eval_duration': 543208000, 'eval_count': 93, 'eval_duration': 42075109000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-d8e7dacd-8504-4cca-afa3-1499abec0ec8-0' usage_metadata={'input_tokens': 39, 'output_tokens': 93, 'total_tokens': 132}\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\"topic\": \"lawyers\", \"count\": 3})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 2**\n",
    "\n",
    "Dengan menggunakan `prompt_template`, `model`, dan juga `StrOutputParser` function.\n",
    "\n",
    "`StrOutputParser` function berfungsi untuk membuat output dari LLM menjadi lebih rapi dengan mem-parser string output nya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three lawyer jokes for you:\n",
      "\n",
      "1. Why did the lawyer's client bring a ladder to their meeting?\n",
      "\n",
      "Because they wanted to take their case to the next level!\n",
      "\n",
      "2. Why did the lawyer become a baker?\n",
      "\n",
      "Because they kneaded the dough!\n",
      "\n",
      "3. What do you call a lawyer who doesn't like coffee?\n",
      "\n",
      "A lawsuit to get one!\n"
     ]
    }
   ],
   "source": [
    "chain = prompt_template | model | StrOutputParser()\n",
    "result = chain.invoke({\"topic\": \"lawyers\", \"count\": 3})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
