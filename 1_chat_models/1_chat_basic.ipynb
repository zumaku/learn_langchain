{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisiasi\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,\n",
    "    \n",
    "    # other params...\n",
    "    # format=\"json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set message\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful translator. Translate the user sentence to Indonesian.\"),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Response\n",
    "\n",
    "Dengan menggunakan `invoke`, sistem akan mengembalikan respons dari LLM jika keseluruhan token telah tergenerate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Saya sangat menyukai pemrograman.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2024-12-01T12:57:39.7314308Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3558472800, 'load_duration': 53848900, 'prompt_eval_count': 42, 'prompt_eval_duration': 1095525000, 'eval_count': 11, 'eval_duration': 2399099000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-9e272653-6913-41a1-ac63-394f18fee697-0' usage_metadata={'input_tokens': 42, 'output_tokens': 11, 'total_tokens': 53}\n"
     ]
    }
   ],
   "source": [
    "# [Direct Response]\n",
    "llm_respons = llm.invoke(messages)\n",
    "print(llm_respons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Response\n",
    "\n",
    "Dengan menggunakan `stream`, sistem akan mengembalikan response untuk setiap token yang tergenerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='S' additional_kwargs={} response_metadata={} id='run-de6b35f1-5eb3-4cc6-9adc-77f3dfe7a2be'\n",
      "content='aya' additional_kwargs={} response_metadata={} id='run-de6b35f1-5eb3-4cc6-9adc-77f3dfe7a2be'\n",
      "content=' sangat' additional_kwargs={} response_metadata={} id='run-de6b35f1-5eb3-4cc6-9adc-77f3dfe7a2be'\n",
      "content=' meny' additional_kwargs={} response_metadata={} id='run-de6b35f1-5eb3-4cc6-9adc-77f3dfe7a2be'\n",
      "content='uk' additional_kwargs={} response_metadata={} id='run-de6b35f1-5eb3-4cc6-9adc-77f3dfe7a2be'\n",
      "content='ai' additional_kwargs={} response_metadata={} id='run-de6b35f1-5eb3-4cc6-9adc-77f3dfe7a2be'\n",
      "content=' pem' additional_kwargs={} response_metadata={} id='run-de6b35f1-5eb3-4cc6-9adc-77f3dfe7a2be'\n",
      "content='rogram' additional_kwargs={} response_metadata={} id='run-de6b35f1-5eb3-4cc6-9adc-77f3dfe7a2be'\n",
      "content='an' additional_kwargs={} response_metadata={} id='run-de6b35f1-5eb3-4cc6-9adc-77f3dfe7a2be'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-de6b35f1-5eb3-4cc6-9adc-77f3dfe7a2be'\n",
      "content='' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2024-12-01T12:57:48.1615021Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3430341800, 'load_duration': 173829000, 'prompt_eval_count': 42, 'prompt_eval_duration': 732971000, 'eval_count': 11, 'eval_duration': 2508918000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-de6b35f1-5eb3-4cc6-9adc-77f3dfe7a2be' usage_metadata={'input_tokens': 42, 'output_tokens': 11, 'total_tokens': 53}\n"
     ]
    }
   ],
   "source": [
    "# [Sream Response]\n",
    "for chunk in llm.stream(messages):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cara lain untuk menggunakan stream respons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saya\n",
      "Saya sangat\n",
      "Saya sangat meny\n",
      "Saya sangat menyuk\n",
      "Saya sangat menyukai\n",
      "Saya sangat menyukai pem\n",
      "Saya sangat menyukai pemrogram\n",
      "Saya sangat menyukai pemrograman\n",
      "Saya sangat menyukai pemrograman.\n",
      "Saya sangat menyukai pemrograman.\n"
     ]
    }
   ],
   "source": [
    "# [Another way to get Stream Response]\n",
    "stream = llm.stream(messages)\n",
    "full = next(stream)\n",
    "for chunk in stream:\n",
    "    full += chunk\n",
    "    # print(full)\n",
    "    print(full.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Format Response\n",
    "\n",
    "Selain ke dua cara di atas, response LLM juga dapat didapat dalam bentuk json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2 = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,\n",
    "    format=\"json\",  # Tambahkan atribut format json\n",
    ")\n",
    "\n",
    "messages2 = [\n",
    "    (\"system\", \"You are a helpful translator. Translate the user sentence to Indonesian.\"),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"en\": \"I love programming.\", \"id\": \"Saya sangat menyukai pemrograman.\"}\n"
     ]
    }
   ],
   "source": [
    "print(llm2.invoke(messages2).content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
